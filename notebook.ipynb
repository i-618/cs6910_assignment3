{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchmetrics import Accuracy\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Script:\n",
    "    def __init__(self, script_name):\n",
    "        self.script_name = script_name\n",
    "        self.char2idx = {}\n",
    "        self.inx2char = {}\n",
    "        self.vocab_size = 0\n",
    "\n",
    "    def create_vocab(self, char_list):\n",
    "        for i, char in enumerate(char_list):\n",
    "            self.char2idx[char] = i\n",
    "            self.inx2char[i] = char\n",
    "        self.vocab_size = len(char_list)\n",
    "    \n",
    "    def add_char(self, char):\n",
    "        if char not in self.char2idx:\n",
    "            self.char2idx[char] = self.vocab_size\n",
    "            self.inx2char[self.vocab_size] = char\n",
    "            self.vocab_size += 1\n",
    "        else:\n",
    "            print(\"Character already exists in the script\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asm', 'ben', 'brx', 'guj', 'hin', 'kan', 'kas', 'kok', 'mai', 'mal', 'mar', 'mni', 'ori', 'pan', 'san', 'sid', 'tam', 'tel', 'urd']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataset_name = \"aksharantar_sampled\"\n",
    "languages_dataset = os.listdir(dataset_name)\n",
    "print(languages_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: {'y_test': 4096, 'y_train': 51200, 'y_val': 4096}\n"
     ]
    }
   ],
   "source": [
    "language = 'kan'\n",
    "START='<'\n",
    "END='>'\n",
    "def load_dataset_csv(path):\n",
    "    X, y = [], []\n",
    "    with open(path, 'r', encoding='UTF-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(',')\n",
    "            X.append(f'{START}{line[0]}{END}')\n",
    "            y.append(f'{START}{line[1]}{END}')\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "list_files = os.listdir(f'{dataset_name}/{language}')\n",
    "path = f'{dataset_name}/{language}'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test, y_test = load_dataset_csv(f'{path}/{language}_test.csv')\n",
    "X_train, y_train = load_dataset_csv(f'{path}/{language}_train.csv')\n",
    "X_val, y_val = load_dataset_csv(f'{path}/{language}_val.csv')\n",
    "\n",
    "print('Dataset size:', {'y_test': len(y_test), 'y_train': len(y_train), 'y_val': len(y_val)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<', 1: '>', 2: 'ಂ', 3: 'ಃ', 4: 'ಅ', 5: 'ಆ', 6: 'ಇ', 7: 'ಈ', 8: 'ಉ', 9: 'ಊ', 10: 'ಋ', 11: 'ಎ', 12: 'ಏ', 13: 'ಐ', 14: 'ಒ', 15: 'ಓ', 16: 'ಔ', 17: 'ಕ', 18: 'ಖ', 19: 'ಗ', 20: 'ಘ', 21: 'ಚ', 22: 'ಛ', 23: 'ಜ', 24: 'ಝ', 25: 'ಞ', 26: 'ಟ', 27: 'ಠ', 28: 'ಡ', 29: 'ಢ', 30: 'ಣ', 31: 'ತ', 32: 'ಥ', 33: 'ದ', 34: 'ಧ', 35: 'ನ', 36: 'ಪ', 37: 'ಫ', 38: 'ಬ', 39: 'ಭ', 40: 'ಮ', 41: 'ಯ', 42: 'ರ', 43: 'ಲ', 44: 'ಳ', 45: 'ವ', 46: 'ಶ', 47: 'ಷ', 48: 'ಸ', 49: 'ಹ', 50: 'ಾ', 51: 'ಿ', 52: 'ೀ', 53: 'ು', 54: 'ೂ', 55: 'ೃ', 56: 'ೆ', 57: 'ೇ', 58: 'ೈ', 59: 'ೊ', 60: 'ೋ', 61: 'ೌ', 62: '್'}\n",
      "{0: '<', 1: '>', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e', 7: 'f', 8: 'g', 9: 'h', 10: 'i', 11: 'j', 12: 'k', 13: 'l', 14: 'm', 15: 'n', 16: 'o', 17: 'p', 18: 'q', 19: 'r', 20: 's', 21: 't', 22: 'u', 23: 'v', 24: 'w', 25: 'x', 26: 'y', 27: 'z'}\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = max([len(x) for x in X_train] + [len(y) for y in y_train])\n",
    "\n",
    "unique_chars = set()\n",
    "[unique_chars.update(list(x)) for x in y_train]\n",
    "unique_chars = list(unique_chars)\n",
    "unique_chars.sort()\n",
    "\n",
    "local_script = Script(language)\n",
    "local_script.create_vocab(unique_chars)\n",
    "print(local_script.inx2char)\n",
    "\n",
    "\n",
    "\n",
    "unique_chars = set()\n",
    "[unique_chars.update(list(x)) for x in X_train]\n",
    "unique_chars = list(unique_chars)\n",
    "unique_chars.sort()\n",
    "\n",
    "latin_script = Script('latin')\n",
    "latin_script.create_vocab(unique_chars)\n",
    "print(latin_script.inx2char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transliter_pairs_test = list(zip(X_test, y_test))\n",
    "transliter_pairs_train = list(zip(X_train, y_train))\n",
    "transliter_pairs_val = list(zip(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(transliter_pairs, latin_script, local_script, batch_size=32):\n",
    "    n = len(transliter_pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=int)\n",
    "    output_ids = np.zeros((n, MAX_LENGTH), dtype=int)\n",
    "\n",
    "\n",
    "    for idx, (latin, local) in enumerate(transliter_pairs):\n",
    "        try:\n",
    "            inp_ids = [latin_script.char2idx[c] for c in latin]\n",
    "            out_ids = [local_script.char2idx[c] for c in local]\n",
    "            input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "            output_ids[idx, :len(out_ids)] = out_ids\n",
    "        except Exception as e:\n",
    "            print(repr(e))\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(output_ids).to(device))\n",
    "    sampler = torch.utils.data.RandomSampler(dataset)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, sampler=sampler, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = get_dataloader(transliter_pairs_train, latin_script, local_script, batch_size=32)\n",
    "dataloader_test = get_dataloader(transliter_pairs_test, latin_script, local_script, batch_size=32)\n",
    "dataloader_val = get_dataloader(transliter_pairs_val, latin_script, local_script, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = torch.nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(0)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = torch.nn.functional.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = torch.nn.functional.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "batch_size=32\n",
    "encoder = Encoder(input_size=latin_script.vocab_size, hidden_size=hidden_size, dropout_p=0).to(device)\n",
    "decoder = DecoderRNN(hidden_size=hidden_size, output_size=local_script.vocab_size).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, accuracy_criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_accuracy = torch.tensor([], dtype=torch.float32, device=device)\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "        accuracy = accuracy_criterion(decoded_ids, target_tensor)\n",
    "        total_accuracy = torch.cat((total_accuracy, accuracy))\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader), total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_val_loss_accuracy(val_dataloader, criterion, encoder, decoder):\n",
    "    total_loss = 0\n",
    "    for data in val_dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        # calcluating accuracy\n",
    "        \n",
    "\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100, val_dataloader=None):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    print_accuracy_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    accuracy_criterion = Accuracy(task='multiclass', num_classes=local_script.vocab_size, multidim_average='samplewise')\n",
    "\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss, accuracy = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, accuracy_criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        print_accuracy_total += sum(accuracy ==1)/len(accuracy)\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_accuracy_avg = print_accuracy_total / print_every\n",
    "            print_accuracy_total = 0\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) Loss: %.4f Acc: %.2f %%' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg, print_accuracy_avg*100))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = train(dataloader_val, encoder, decoder, 50, print_every=1, plot_every=1)\n",
    "\n",
    "# for i in range(1000):\n",
    "#     losss = train_epoch(dataloader, encoder, decoder, torch.optim.Adam(encoder.parameters()), torch.optim.Adam(decoder.parameters()), torch.nn.NLLLoss())\n",
    "#     print(losss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = iter(dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ['<nadesabekendu>', '<samataavadi>', '<tru>', '<janasankhyege>', '<ganigalu>', '<padedukondavarella>', '<dakshatheyannu>', '<mahaparadhavenendare>', '<itihaasada>', '<tombhattarusavira>', '<thor>', '<gnanamitrappa>', '<sangharshadalli>', '<rangapraveshakkoo>', '<baruttiddaru>', '<gidamoolikegalinda>', '<nalacharitre>', '<soni>', '<bahusankhyeyallidda>', '<ratnagalannu>', '<vyaaptiyinda>', '<shaahi>', '<kaalininda>', '<saranigalalli>', '<adyano>', '<vishvavidyaanilayagala>', '<pattehachchida>', '<muvataidu>', '<barmaa>', '<ennalaguttide>', '<janasankhyeayoo>', '<intelligence>']\n",
      "Expected: ['<ನಡೆಸಬೇಕೆಂದು>', '<ಸಮತಾವಾದಿ>', '<ಟ್ರೂ>', '<ಜನಸಂಖ್ಯೆಗೆ>', '<ಗಣಿಗಳು>', '<ಪಡೆದುಕೊಂಡವರೆಲ್ಲಾ>', '<ದಕ್ಷತೆಯನ್ನು>', '<ಮಹಾಪರಾಧವೇನೆಂದರೆ>', '<ಇತಿಹಾಸದ>', '<ತೊಂಭತ್ತಾರುಸಾವಿರ>', '<ಥಾರ್>', '<ಜ್ಞಾನಮಿತ್ರಪ್ಪ>', '<ಸಂಘರ್ಷದಲ್ಲಿ>', '<ರಂಗಪ್ರವೇಶಕ್ಕೂ>', '<ಬರುತ್ತಿದ್ದರು>', '<ಗಿಡಮೂಲಿಕೆಗಳಿಂದ>', '<ನಳಚರಿತ್ರೆ>', '<ಸೋನಿ>', '<ಬಹುಸಂಖ್ಯೆಯಲ್ಲಿದ್ದ>', '<ರತ್ನಗಳನ್ನು>', '<ವ್ಯಾಪ್ತಿಯಿಂದ>', '<ಶಾಹಿ>', '<ಕಾಲಿನಿಂದ>', '<ಸರಣಿಗಳಲ್ಲಿ>', '<ಅದ್ಯಾನೋ>', '<ವಿಶ್ವವಿದ್ಯಾನಿಲಯಗಳ>', '<ಪತ್ತೆಹಚ್ಚಿದ>', '<ಮುವತೈದು>', '<ಬರ್ಮಾ>', '<ಎನ್ನಲಾಗುತ್ತಿದೆ>', '<ಜನಸಂಖ್ಯೆಯೂ>', '<ಇಂಟೆಲಿಜೆನ್ಸ್>']\n",
      "Predicted: ['ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ೌಿಥಿಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ', 'ಮಲೌಐಐನಭೌಐಐವಐವವಐವವಮಢೋಃಮೊೊಒಐಐಠಘ']\n",
      "Accuracy:   0.0\n",
      "Matched:  set()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convert_tensor_to_string(tensor, script):\n",
    "    words = []\n",
    "    for idx in tensor:\n",
    "        word = []\n",
    "        for i in idx:\n",
    "            word.append(script.inx2char[i.item()])\n",
    "            if i.item() == script.char2idx[END]:\n",
    "                break\n",
    "        words.append(''.join(word))\n",
    "    return words\n",
    "\n",
    "input_tensor, target_tensor = next(test_data)\n",
    "encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "_, topi = decoder_outputs.topk(1)\n",
    "decoded_ids = topi.squeeze()\n",
    "\n",
    "input_words, output_words = convert_tensor_to_string(input_tensor, latin_script), convert_tensor_to_string(decoded_ids, local_script)\n",
    "expected_words = convert_tensor_to_string(target_tensor, local_script)\n",
    "\n",
    "print('Input:', input_words)\n",
    "print('Expected:', expected_words)\n",
    "print('Predicted:', output_words)\n",
    "\n",
    "matched_words = set(expected_words) & set(output_words)\n",
    "print('Accuracy:  ', len(matched_words)/ len(expected_words))\n",
    "print('Matched: ', matched_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(torch.nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = torch.nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(0)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = torch.nn.functional.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_size=latin_script.vocab_size, hidden_size=hidden_size, dropout_p=0).to(device)\n",
    "attn_decoder = AttnDecoderRNN(hidden_size=hidden_size, output_size=local_script.vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 7s (- 1m 9s) (1 10%) Loss: 1.2286 Acc: 0.00 %\n",
      "0m 14s (- 0m 59s) (2 20%) Loss: 0.8457 Acc: 0.00 %\n",
      "0m 22s (- 0m 51s) (3 30%) Loss: 0.6599 Acc: 0.07 %\n",
      "0m 29s (- 0m 43s) (4 40%) Loss: 0.3838 Acc: 6.67 %\n",
      "0m 36s (- 0m 36s) (5 50%) Loss: 0.2171 Acc: 19.75 %\n",
      "0m 43s (- 0m 29s) (6 60%) Loss: 0.1576 Acc: 28.59 %\n",
      "0m 50s (- 0m 21s) (7 70%) Loss: 0.1302 Acc: 34.74 %\n",
      "0m 58s (- 0m 14s) (8 80%) Loss: 0.1107 Acc: 40.48 %\n",
      "1m 5s (- 0m 7s) (9 90%) Loss: 0.0969 Acc: 44.73 %\n",
      "1m 12s (- 0m 0s) (10 100%) Loss: 0.0847 Acc: 49.24 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.22861702227965,\n",
       " 0.8456838964484632,\n",
       " 0.6598509564064443,\n",
       " 0.3838379685766995,\n",
       " 0.21712106140330434,\n",
       " 0.15762696106685326,\n",
       " 0.1302093081176281,\n",
       " 0.11067942302906886,\n",
       " 0.09691502572968602,\n",
       " 0.08467209115042351]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(dataloader_val, encoder, attn_decoder, 10, print_every=1, plot_every=1, val_dataloader=dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_tensor_to_string(tensor, script):\n",
    "    words = []\n",
    "    for idx in tensor:\n",
    "        word = []\n",
    "        for i in idx:\n",
    "            if i.item() == script.char2idx[START]:\n",
    "                continue\n",
    "            if i.item() == script.char2idx[END]:\n",
    "                break\n",
    "            word.append(script.inx2char[i.item()])\n",
    "        words.append(''.join(word))\n",
    "    return words\n",
    "\n",
    "\n",
    "for data in dataloader_test:\n",
    "        input_tensor, target_tensor = data\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = attn_decoder(encoder_outputs, encoder_hidden)\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "        input_words, output_words = convert_tensor_to_string(input_tensor, latin_script), convert_tensor_to_string(decoded_ids, local_script)\n",
    "        expected_words = convert_tensor_to_string(target_tensor, local_script)\n",
    "        with open('test_predictions.csv', 'a', encoding=\"utf-8\") as f:\n",
    "                for i in range(len(input_words)):\n",
    "                        f.write(f'{input_words[i]},{expected_words[i]},{output_words[i]}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ['<gavanmentinu>', '<chikithsichumaattaam>', '<sadanam>', '<varikalaanu>', '<kombukalum>', '<kanjangad>', '<maidrid>', '<jorj>', '<manthrisabhaayogathine>', '<swadeshiyum>', '<anusarichum>', '<aswasthathayoyaanu>', '<faashisttaaya>', '<karnaadakathilum>', '<auak>', '<bora>', '<aashankaanimisham>', '<ruupappedunnathu>', '<chinayilum>', '<panjcha>', '<grafic>', '<vimanangale>', '<samarthamaaya>', '<dikkil>', '<adukkurippodeyaanu>', '<midhyayo>', '<thudarendennu>', '<aadyathil>', '<pappanum>', '<aduthethaanaakoo>', '<raashtreeyabhethamanye>', '<indirayude>']\n",
      "Expected: ['<ഗവൺമെന്റിന്>', '<ചികിത്സിച്ചുമാറ്റാം>', '<സദനം>', '<വരികളാണ്>', '<കൊമ്പുകളും>', '<കാഞ്ഞങ്ങാട്>', '<മാഡ്രിഡ്>', '<ജോര്ജ്>', '<മന്ത്രിസഭായോഗത്തിനേ>', '<സ്വദേശിയും>', '<അനുസരിച്ചും>', '<അസ്വസ്ഥതയോയാണ്>', '<ഫാഷിസ്റ്റായ>', '<കർണാടകത്തിലും>', '<ഓക്ക്>', '<ബോറ>', '<ആശങ്കാനിമിഷം>', '<രൂപപ്പെടുന്നത്>', '<ചൈനയിലും>', '<പഞ്ച>', '<ഗ്രാഫിക്>', '<വിമാനങ്ങളെ>', '<സമർഥമായ>', '<ദിക്കിൽ>', '<അടുക്കുറിപ്പോടെയാണ്>', '<മിഥ്യയോ>', '<തുടരേണ്ടെന്നു>', '<ആദ്യത്തിൽ>', '<പപ്പനും>', '<അടുത്തെത്താനാകൂ>', '<രാഷ്ട്രീയഭേതമന്യേ>', '<ഇന്ദിരയുടെ>']\n",
      "Predicted: ['<ഗവന്മെന്റിന്>', '<ചികിത്സിച്ചുമാട്>', '<സദനം>', '<വരികളാണ്>', '<കൊമ്പുകളും>', '<കഞ്ഞങ്ങട്>', '<മൈഡ്രിഡ്>', '<ജോർജ്>', '<മന്ത്രിസഭായോഗത്തിനെ>', '<സ്വദേശിയും>', '<അനുസരിച്ചും>', '<അസ്വസ്ഥതയോയാണ്>', '<ഫാഷിസ്റ്റായ>', '<കർണാടകത്തിലും>', '<ആക്ക്>', '<ബോറ>', '<ആശങ്കാനിമിഷം>', '<രൂപപ്പെടുന്നത്>', '<ചിനയിലും>', '<പഞ്ച>', '<ഗ്രാഫിക്>', '<വിമാനങ്ങളെ>', '<സമർതമായ>', '<ഡിക്കിൽ>', '<അടുക്കുറിപ്പോടെയാണ്>', '<മിധ്യയോ>', '<തുടരെന്ദെന്നു>', '<ആദ്യത്തിൽ>', '<പപ്പനും>', '<അടുത്തേത്താനാകൂകോ>', '<രാശ്ത്രീയഭേതമനെ>', '<ഇന്ദിരയുടെ>']\n",
      "Accuracy:   0.5625\n",
      "Matched:  {'<വരികളാണ്>', '<ആദ്യത്തിൽ>', '<അസ്വസ്ഥതയോയാണ്>', '<കൊമ്പുകളും>', '<ഫാഷിസ്റ്റായ>', '<സദനം>', '<രൂപപ്പെടുന്നത്>', '<ഗ്രാഫിക്>', '<ആശങ്കാനിമിഷം>', '<അടുക്കുറിപ്പോടെയാണ്>', '<പഞ്ച>', '<അനുസരിച്ചും>', '<ബോറ>', '<പപ്പനും>', '<ഇന്ദിരയുടെ>', '<വിമാനങ്ങളെ>', '<കർണാടകത്തിലും>', '<സ്വദേശിയും>'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convert_tensor_to_string(tensor, script):\n",
    "    words = []\n",
    "    for idx in tensor:\n",
    "        word = []\n",
    "        for i in idx:\n",
    "            if i.item() == script.char2idx[START]:\n",
    "                continue\n",
    "            if i.item() == script.char2idx[END]:\n",
    "                break\n",
    "            word.append(script.inx2char[i.item()])\n",
    "        words.append(''.join(word))\n",
    "    return words\n",
    "\n",
    "input_tensor, target_tensor = next(test_data)\n",
    "encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "decoder_outputs, _, _ = attn_decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "_, topi = decoder_outputs.topk(1)\n",
    "decoded_ids = topi.squeeze()\n",
    "\n",
    "input_words, output_words = convert_tensor_to_string(input_tensor, latin_script), convert_tensor_to_string(decoded_ids, local_script)\n",
    "expected_words = convert_tensor_to_string(target_tensor, local_script)\n",
    "\n",
    "print('Input:', input_words)\n",
    "print('Expected:', expected_words)\n",
    "print('Predicted:', output_words)\n",
    "\n",
    "matched_words = set(expected_words) & set(output_words)\n",
    "print('Accuracy:  ', len(matched_words)/ len(expected_words))\n",
    "print('Matched: ', matched_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mns24z066\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\likhi\\Music\\TCS\\MS\\FDL\\Assignments\\Assignment_3\\cs6910_assignment3\\wandb\\run-20240517_063030-gpgdytb4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ns24z066/CS6910-Assignment-3/runs/gpgdytb4' target=\"_blank\">rosy-wave-196</a></strong> to <a href='https://wandb.ai/ns24z066/CS6910-Assignment-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ns24z066/CS6910-Assignment-3' target=\"_blank\">https://wandb.ai/ns24z066/CS6910-Assignment-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ns24z066/CS6910-Assignment-3/runs/gpgdytb4' target=\"_blank\">https://wandb.ai/ns24z066/CS6910-Assignment-3/runs/gpgdytb4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 7f04l1qk\n",
      "Sweep URL: https://wandb.ai/ns24z066/CS6910-Assignment-3/sweeps/7f04l1qk\n",
      "7f04l1qk\n"
     ]
    }
   ],
   "source": [
    "import wandb, json\n",
    "\n",
    "wandb.init(project='CS6910-Assignment-3')\n",
    "\n",
    "with open('sweep-config.json') as f:\n",
    "    sweep_config = json.load(f)\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='CS6910-Assignment-3')\n",
    "print(sweep_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
