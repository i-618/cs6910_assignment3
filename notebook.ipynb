{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Script:\n",
    "    def __init__(self, script_name):\n",
    "        self.script_name = script_name\n",
    "        self.char2idx = {}\n",
    "        self.inx2char = {}\n",
    "        self.vocab_size = 0\n",
    "\n",
    "    def create_vocab(self, char_list):\n",
    "        for i, char in enumerate(char_list):\n",
    "            self.char2idx[char] = i\n",
    "            self.inx2char[i] = char\n",
    "        self.vocab_size = len(char_list)\n",
    "    \n",
    "    def add_char(self, char):\n",
    "        if char not in self.char2idx:\n",
    "            self.char2idx[char] = self.vocab_size\n",
    "            self.inx2char[self.vocab_size] = char\n",
    "            self.vocab_size += 1\n",
    "        else:\n",
    "            print(\"Character already exists in the script\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asm', 'ben', 'brx', 'guj', 'hin', 'kan', 'kas', 'kok', 'mai', 'mal', 'mar', 'mni', 'ori', 'pan', 'san', 'sid', 'tam', 'tel', 'urd']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataset_name = \"aksharantar_sampled\"\n",
    "languages_dataset = os.listdir(dataset_name)\n",
    "print(languages_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH=10\n",
    "language = 'kan'\n",
    "START='<'\n",
    "END='>'\n",
    "def load_dataset_csv(path):\n",
    "    X, y = [], []\n",
    "    with open(path, 'r', encoding='UTF-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(',')\n",
    "            X.append(f'{START}{line[0]}{END}')\n",
    "            y.append(f'{START}{line[1]}{END}')\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "list_files = os.listdir(f'{dataset_name}/{language}')\n",
    "path = f'{dataset_name}/{language}'\n",
    "X_test, y_test = load_dataset_csv(f'{path}/{list_files[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = max([len(x) for x in X_test] + [len(y) for y in y_test])\n",
    "\n",
    "unique_chars = set()\n",
    "[unique_chars.update(list(x)) for x in y_test]\n",
    "unique_chars = list(unique_chars)\n",
    "unique_chars.sort()\n",
    "\n",
    "local_script = Script(language)\n",
    "local_script.create_vocab(unique_chars)\n",
    "local_script.inx2char\n",
    "\n",
    "unique_chars = set()\n",
    "[unique_chars.update(list(x)) for x in X_test]\n",
    "unique_chars = list(unique_chars)\n",
    "unique_chars.sort()\n",
    "\n",
    "latin_script = Script('latin')\n",
    "latin_script.create_vocab(unique_chars)\n",
    "# latin_script.inx2char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transliter_pairs = list(zip(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(transliter_pairs, latin_script, local_script, batch_size=32):\n",
    "    n = len(transliter_pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=int)\n",
    "    output_ids = np.zeros((n, MAX_LENGTH), dtype=int)\n",
    "\n",
    "\n",
    "    for idx, (latin, local) in enumerate(transliter_pairs):\n",
    "        inp_ids = [latin_script.char2idx[c] for c in latin]\n",
    "        out_ids = [local_script.char2idx[c] for c in local]\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        output_ids[idx, :len(out_ids)] = out_ids\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(output_ids).to(device))\n",
    "    sampler = torch.utils.data.RandomSampler(dataset)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, sampler=sampler, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dataloader(transliter_pairs, latin_script, local_script, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = torch.nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(0)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = torch.nn.functional.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = torch.nn.functional.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "batch_size=32\n",
    "encoder = Encoder(latin_script.vocab_size, hidden_size, dropout_p=0).to(device)\n",
    "decoder = DecoderRNN(hidden_size, local_script.vocab_size).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 3s (- 5m 24s) (1 1%) 0.0248\n",
      "0m 6s (- 5m 10s) (2 2%) 0.0120\n",
      "0m 9s (- 5m 3s) (3 3%) 0.0099\n",
      "0m 12s (- 4m 59s) (4 4%) 0.0121\n",
      "0m 15s (- 4m 55s) (5 5%) 0.0584\n",
      "0m 18s (- 4m 52s) (6 6%) 0.0675\n",
      "0m 21s (- 4m 49s) (7 7%) 0.0245\n",
      "0m 24s (- 4m 46s) (8 8%) 0.0117\n",
      "0m 28s (- 4m 43s) (9 9%) 0.0079\n",
      "0m 31s (- 4m 39s) (10 10%) 0.0065\n",
      "0m 34s (- 4m 36s) (11 11%) 0.0057\n",
      "0m 37s (- 4m 33s) (12 12%) 0.0054\n",
      "0m 40s (- 4m 29s) (13 13%) 0.0051\n",
      "0m 43s (- 4m 26s) (14 14%) 0.0048\n",
      "0m 46s (- 4m 23s) (15 15%) 0.0047\n",
      "0m 49s (- 4m 20s) (16 16%) 0.0046\n",
      "0m 52s (- 4m 17s) (17 17%) 0.0153\n",
      "0m 55s (- 4m 13s) (18 18%) 0.1508\n",
      "0m 58s (- 4m 10s) (19 19%) 0.0717\n",
      "1m 1s (- 4m 7s) (20 20%) 0.0321\n",
      "1m 4s (- 4m 4s) (21 21%) 0.0166\n",
      "1m 8s (- 4m 1s) (22 22%) 0.0095\n",
      "1m 11s (- 3m 58s) (23 23%) 0.0067\n",
      "1m 14s (- 3m 55s) (24 24%) 0.0057\n",
      "1m 17s (- 3m 52s) (25 25%) 0.0051\n",
      "1m 20s (- 3m 48s) (26 26%) 0.0049\n",
      "1m 23s (- 3m 45s) (27 27%) 0.0046\n",
      "1m 26s (- 3m 42s) (28 28%) 0.0043\n",
      "1m 29s (- 3m 39s) (29 28%) 0.0041\n",
      "1m 32s (- 3m 36s) (30 30%) 0.0040\n",
      "1m 35s (- 3m 33s) (31 31%) 0.0039\n",
      "1m 38s (- 3m 30s) (32 32%) 0.0038\n",
      "1m 42s (- 3m 27s) (33 33%) 0.0049\n",
      "1m 45s (- 3m 23s) (34 34%) 0.0529\n",
      "1m 48s (- 3m 20s) (35 35%) 0.1611\n",
      "1m 51s (- 3m 17s) (36 36%) 0.0647\n",
      "1m 54s (- 3m 14s) (37 37%) 0.0283\n",
      "1m 57s (- 3m 11s) (38 38%) 0.0144\n",
      "2m 0s (- 3m 8s) (39 39%) 0.0090\n",
      "2m 3s (- 3m 5s) (40 40%) 0.0064\n",
      "2m 6s (- 3m 2s) (41 41%) 0.0054\n",
      "2m 9s (- 2m 59s) (42 42%) 0.0048\n",
      "2m 12s (- 2m 56s) (43 43%) 0.0044\n",
      "2m 15s (- 2m 52s) (44 44%) 0.0042\n",
      "2m 18s (- 2m 49s) (45 45%) 0.0040\n",
      "2m 21s (- 2m 46s) (46 46%) 0.0038\n",
      "2m 25s (- 2m 43s) (47 47%) 0.0036\n",
      "2m 28s (- 2m 40s) (48 48%) 0.0038\n",
      "2m 31s (- 2m 37s) (49 49%) 0.0043\n",
      "2m 34s (- 2m 34s) (50 50%) 0.0204\n",
      "2m 37s (- 2m 31s) (51 51%) 0.1442\n",
      "2m 40s (- 2m 28s) (52 52%) 0.0732\n",
      "2m 43s (- 2m 25s) (53 53%) 0.0280\n",
      "2m 46s (- 2m 22s) (54 54%) 0.0144\n",
      "2m 49s (- 2m 19s) (55 55%) 0.0087\n",
      "2m 53s (- 2m 16s) (56 56%) 0.0061\n",
      "2m 56s (- 2m 12s) (57 56%) 0.0049\n",
      "2m 59s (- 2m 9s) (58 57%) 0.0044\n",
      "3m 2s (- 2m 6s) (59 59%) 0.0041\n",
      "3m 5s (- 2m 3s) (60 60%) 0.0038\n",
      "3m 8s (- 2m 0s) (61 61%) 0.0036\n",
      "3m 11s (- 1m 57s) (62 62%) 0.0033\n",
      "3m 14s (- 1m 54s) (63 63%) 0.0032\n",
      "3m 17s (- 1m 51s) (64 64%) 0.0031\n",
      "3m 21s (- 1m 48s) (65 65%) 0.0030\n",
      "3m 24s (- 1m 45s) (66 66%) 0.0029\n",
      "3m 27s (- 1m 42s) (67 67%) 0.0029\n",
      "3m 30s (- 1m 39s) (68 68%) 0.0027\n",
      "3m 33s (- 1m 35s) (69 69%) 0.0026\n",
      "3m 36s (- 1m 32s) (70 70%) 0.0027\n",
      "3m 39s (- 1m 29s) (71 71%) 0.0032\n",
      "3m 42s (- 1m 26s) (72 72%) 0.1650\n",
      "3m 46s (- 1m 23s) (73 73%) 0.1310\n",
      "3m 49s (- 1m 20s) (74 74%) 0.0546\n",
      "3m 53s (- 1m 17s) (75 75%) 0.0264\n",
      "3m 56s (- 1m 14s) (76 76%) 0.0148\n",
      "3m 59s (- 1m 11s) (77 77%) 0.0085\n",
      "4m 2s (- 1m 8s) (78 78%) 0.0058\n",
      "4m 6s (- 1m 5s) (79 79%) 0.0047\n",
      "4m 9s (- 1m 2s) (80 80%) 0.0041\n",
      "4m 12s (- 0m 59s) (81 81%) 0.0038\n",
      "4m 15s (- 0m 56s) (82 82%) 0.0035\n",
      "4m 18s (- 0m 52s) (83 83%) 0.0034\n",
      "4m 21s (- 0m 49s) (84 84%) 0.0031\n",
      "4m 24s (- 0m 46s) (85 85%) 0.0030\n",
      "4m 28s (- 0m 43s) (86 86%) 0.0030\n",
      "4m 31s (- 0m 40s) (87 87%) 0.0029\n",
      "4m 34s (- 0m 37s) (88 88%) 0.0029\n",
      "4m 37s (- 0m 34s) (89 89%) 0.0037\n",
      "4m 40s (- 0m 31s) (90 90%) 0.0464\n",
      "4m 43s (- 0m 28s) (91 91%) 0.1186\n",
      "4m 46s (- 0m 24s) (92 92%) 0.0662\n",
      "4m 49s (- 0m 21s) (93 93%) 0.0295\n",
      "4m 52s (- 0m 18s) (94 94%) 0.0158\n",
      "4m 56s (- 0m 15s) (95 95%) 0.0090\n",
      "4m 59s (- 0m 12s) (96 96%) 0.0057\n",
      "5m 2s (- 0m 9s) (97 97%) 0.0043\n",
      "5m 6s (- 0m 6s) (98 98%) 0.0038\n",
      "5m 9s (- 0m 3s) (99 99%) 0.0033\n",
      "5m 13s (- 0m 0s) (100 100%) 0.0031\n"
     ]
    }
   ],
   "source": [
    "train(dataloader, encoder, decoder, 100, print_every=1, plot_every=1)\n",
    "\n",
    "# for i in range(1000):\n",
    "#     losss = train_epoch(dataloader, encoder, decoder, torch.optim.Adam(encoder.parameters()), torch.optim.Adam(decoder.parameters()), torch.nn.NLLLoss())\n",
    "#     print(losss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <meelmaige><<<<<<<<<<<<<<<<<<<mudisiddare><<<<<<<<<<<<<<<<<ganithashatradalli><<<<<<<<<<prastaavaneyannu><<<<<<<<<<<<beleh><<<<<<<<<<<<<<<<<<<<<<<beledaaga><<<<<<<<<<<<<<<<<<<sitrik><<<<<<<<<<<<<<<<<<<<<<badalaayisikondiddarinda><<<<nindisy><<<<<<<<<<<<<<<<<<<<<modhalindha><<<<<<<<<<<<<<<<<lot><<<<<<<<<<<<<<<<<<<<<<<<<vaasaviddaru><<<<<<<<<<<<<<<<rub><<<<<<<<<<<<<<<<<<<<<<<<<heggalikeyendae><<<<<<<<<<<<<vishvavidyanilayadalli><<<<<<vishvavyapiyagi><<<<<<<<<<<<<kalalu><<<<<<<<<<<<<<<<<<<<<<worldwide><<<<<<<<<<<<<<<<<<<enilla><<<<<<<<<<<<<<<<<<<<<<ariyada><<<<<<<<<<<<<<<<<<<<<jategoodi><<<<<<<<<<<<<<<<<<<vikary><<<<<<<<<<<<<<<<<<<<<<horaduttaliddevu><<<<<<<<<<<<gidamoolike><<<<<<<<<<<<<<<<<saamaanyagolisuvudakke><<<<<<pattiyalliruvudaralli><<<<<<<kurudara><<<<<<<<<<<<<<<<<<<<svacchagolisalendu><<<<<<<<<<isuzu><<<<<<<<<<<<<<<<<<<<<<<ed><<<<<<<<<<<<<<<<<<<<<<<<<<janapratinidhigalu><<<<<<<<<<embante><<<<<<<<<<<<<<<<<<<<\n",
      "Predicted: <ಮೇಲ್ಮೈಗೆ><<<<<<<<<<<<<<<<<<<<ಮೂಡಿಸಿದ್ದಾರೆ><<<<<<<<<<<<<<<<ಗಣಿತಶಾಸ್ತ್ರದಲ್ಲಿ><<<<<<<<<<<<ಪ್ರಸ್ತಾವನೆಯನ್ನು><<<<<<<<<<<<<ಬೆಲೆಃ><<<<<<<<<<<<<<<<<<<<<<<ಬೆಳೆದಾಗ><<<<<<<<<<<<<<<<<<<<<ಸಿಟ್ರಿಕ್><<<<<<<<<<<<<<<<<<<<ಬದಲಾಯಿಸಿಕೊಂಡಿದ್ದರಿಂದ><<<<<<<<ನಿಂದಿಸಿ><<<<<<<<<<<<<<<<<<<<<ಮೊದಲಿಂದ><<<<<<<<<<<<<<<<<<<<<ಲಾಟ್><<<<<<<<<<<<<<<<<<<<<<<<ವಾಸವಿದ್ದರು><<<<<<<<<<<<<<<<<<ರಾಬ್><<<<<<<<<<<<<<<<<<<<<<<<ಹೆಗ್ಗಳಿಕೆಯೇಂದರ><<<<<<<<<<<<<<ವಿಶ್ವವಿದ್ಯಾನಿಲಯದಿ್ಲಿ><<<<<<<<ವಿಶ್ವವ್ಯಾಪಿಯಾಗಿ><<<<<<<<<<<<<ಕಲಲಾಳು><<<<<<<<<<<<<<<<<<<<<<ವರ್ಲ್ಡವೈಡ್ರ<<<<<<<<<<<<<<<<<<ಏನಿಲ್ಲ><<<<<<<<<<<<<<<<<<<<<<ಅರಿಯದ><<<<<<<<<<<<<<<<<<<<<<<ಜತೆಗೂಡಿ><<<<<<<<<<<<<<<<<<<<<ವಿಕಾರಿ><<<<<<<<<<<<<<<<<<<<<<ಹೊರಡುತ್ತಲಿದ್ದೆವು><<<<<<<<<<<<ಗಿಲಮೂಲಿದೆ><<<<<<<<<<<<<<<<<<<ಸಾಮಾನ್ಯಗೊಳಿಸುವುದಕ್ಕೆ><<<<<<<<ಪಟ್ಟಿಯಲ್ಲಿರುವುದರಿ್ಲಿರ<<<<<<<<ಕುರುರರ><<<<<<<<<<<<<<<<<<<<<<ಸ್ವಚ್ಛಗೊಳಿಸಲೆಂದು><<<<<<<<<<<<ಇಸುಜು><<<<<<<<<<<<<<<<<<<<<<<ಎಡ್><<<<<<<<<<<<<<<<<<<<<<<<<ಜನಪ್ರತಿನಿಧಿಗಳು><<<<<<<<<<<<<<ಎಂಬಂಥೆ><<<<<<<<<<<<<<<<<<<<<\n",
      "Label: <ಮೇಲ್ಮೈಗೆ><<<<<<<<<<<<<<<<<<<<ಮೂಡಿಸಿದ್ದಾರೆ><<<<<<<<<<<<<<<<ಗಣಿತಶಾಸ್ತ್ರದಲ್ಲಿ><<<<<<<<<<<<ಪ್ರಸ್ತಾವನೆಯನ್ನು><<<<<<<<<<<<<ಬೆಲೆಃ><<<<<<<<<<<<<<<<<<<<<<<ಬೆಳೆದಾಗ><<<<<<<<<<<<<<<<<<<<<ಸಿಟ್ರಿಕ್><<<<<<<<<<<<<<<<<<<<ಬದಲಾಯಿಸಿಕೊಂಡಿದ್ದರಿಂದ><<<<<<<<ನಿಂದಿಸಿ><<<<<<<<<<<<<<<<<<<<<ಮೊದಲಿಂದ><<<<<<<<<<<<<<<<<<<<<ಲಾಟ್><<<<<<<<<<<<<<<<<<<<<<<<ವಾಸವಿದ್ದರು><<<<<<<<<<<<<<<<<<ರಾಬ್><<<<<<<<<<<<<<<<<<<<<<<<ಹೆಗ್ಗಳಿಕೆಯೆಂದೇ><<<<<<<<<<<<<<ವಿಶ್ವವಿದ್ಯಾನಿಲಯದಲ್ಲಿ><<<<<<<<ವಿಶ್ವವ್ಯಾಪಿಯಾಗಿ><<<<<<<<<<<<<ಕಾಲಾಳು><<<<<<<<<<<<<<<<<<<<<<ವರ್ಲ್ಡವೈಡ್><<<<<<<<<<<<<<<<<<ಏನಿಲ್ಲ><<<<<<<<<<<<<<<<<<<<<<ಅರಿಯದ><<<<<<<<<<<<<<<<<<<<<<<ಜತೆಗೂಡಿ><<<<<<<<<<<<<<<<<<<<<ವಿಕಾರಿ><<<<<<<<<<<<<<<<<<<<<<ಹೊರಡುತ್ತಲಿದ್ದೆವು><<<<<<<<<<<<ಗಿಡಮೂಲಿಕೆ><<<<<<<<<<<<<<<<<<<ಸಾಮಾನ್ಯಗೊಳಿಸುವುದಕ್ಕೆ><<<<<<<<ಪಟ್ಟಿಯಲ್ಲಿರುವುದರಲ್ಲಿ><<<<<<<<ಕುರುಡರ><<<<<<<<<<<<<<<<<<<<<<ಸ್ವಚ್ಛಗೊಳಿಸಲೆಂದು><<<<<<<<<<<<ಇಸುಜು><<<<<<<<<<<<<<<<<<<<<<<ಎಡ್><<<<<<<<<<<<<<<<<<<<<<<<<ಜನಪ್ರತಿನಿಧಿಗಳು><<<<<<<<<<<<<<ಎಂಬಂತೆ><<<<<<<<<<<<<<<<<<<<<\n"
     ]
    }
   ],
   "source": [
    "encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "\n",
    "\n",
    "_, topi = decoder_outputs.topk(1)\n",
    "decoded_ids = topi.squeeze()\n",
    "\n",
    "decoded_input = []\n",
    "for inp in input_tensor:\n",
    "    for idx in inp:\n",
    "        if idx.item() == END:\n",
    "            break\n",
    "        decoded_input.append(latin_script.inx2char[idx.item()])\n",
    "\n",
    "print('Input:',''.join(decoded_input))\n",
    "\n",
    "decoded_words = []\n",
    "for idx in decoded_ids:\n",
    "    for i in idx:\n",
    "        if i.item() == END:\n",
    "            break\n",
    "        decoded_words.append(local_script.inx2char[i.item()])\n",
    "    # if idx.item() == END:\n",
    "    #     decoded_words.append('<EOS>')\n",
    "    #     break\n",
    "    # decoded_words.append(local_script.inx2char[idx.item()])\n",
    "print('Predicted:',''.join(decoded_words))\n",
    "\n",
    "actual_word =  []\n",
    "for lbl in target_tensor:\n",
    "    for i in lbl:\n",
    "        if i.item() == END:\n",
    "            break\n",
    "        actual_word.append(local_script.inx2char[i.item()])\n",
    "\n",
    "print('Label:', ''.join(actual_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
