{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchmetrics import Accuracy\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Script:\n",
    "    def __init__(self, script_name):\n",
    "        self.script_name = script_name\n",
    "        self.char2idx = {}\n",
    "        self.inx2char = {}\n",
    "        self.vocab_size = 0\n",
    "\n",
    "    def create_vocab(self, char_list):\n",
    "        for i, char in enumerate(char_list):\n",
    "            self.char2idx[char] = i\n",
    "            self.inx2char[i] = char\n",
    "        self.vocab_size = len(char_list)\n",
    "    \n",
    "    def add_char(self, char):\n",
    "        if char not in self.char2idx:\n",
    "            self.char2idx[char] = self.vocab_size\n",
    "            self.inx2char[self.vocab_size] = char\n",
    "            self.vocab_size += 1\n",
    "        else:\n",
    "            print(\"Character already exists in the script\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asm', 'ben', 'brx', 'guj', 'hin', 'kan', 'kas', 'kok', 'mai', 'mal', 'mar', 'mni', 'ori', 'pan', 'san', 'sid', 'tam', 'tel', 'urd']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataset_name = \"aksharantar_sampled\"\n",
    "languages_dataset = os.listdir(dataset_name)\n",
    "print(languages_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: {'y_test': 4096, 'y_train': 51200, 'y_val': 4096}\n"
     ]
    }
   ],
   "source": [
    "language = 'kan'\n",
    "START='<'\n",
    "END='>'\n",
    "def load_dataset_csv(path):\n",
    "    X, y = [], []\n",
    "    with open(path, 'r', encoding='UTF-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(',')\n",
    "            X.append(f'{START}{line[0]}{END}')\n",
    "            y.append(f'{START}{line[1]}{END}')\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "list_files = os.listdir(f'{dataset_name}/{language}')\n",
    "path = f'{dataset_name}/{language}'\n",
    "\n",
    "\n",
    "\n",
    "X_test, y_test = load_dataset_csv(f'{path}/{list_files[0]}')\n",
    "X_train, y_train = load_dataset_csv(f'{path}/{list_files[1]}')\n",
    "X_val, y_val = load_dataset_csv(f'{path}/{list_files[2]}')\n",
    "\n",
    "print('Dataset size:', {'y_test': len(y_test), 'y_train': len(y_train), 'y_val': len(y_val)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<', 1: '>', 2: 'ಂ', 3: 'ಃ', 4: 'ಅ', 5: 'ಆ', 6: 'ಇ', 7: 'ಈ', 8: 'ಉ', 9: 'ಊ', 10: 'ಋ', 11: 'ಎ', 12: 'ಏ', 13: 'ಐ', 14: 'ಒ', 15: 'ಓ', 16: 'ಔ', 17: 'ಕ', 18: 'ಖ', 19: 'ಗ', 20: 'ಘ', 21: 'ಚ', 22: 'ಛ', 23: 'ಜ', 24: 'ಝ', 25: 'ಞ', 26: 'ಟ', 27: 'ಠ', 28: 'ಡ', 29: 'ಢ', 30: 'ಣ', 31: 'ತ', 32: 'ಥ', 33: 'ದ', 34: 'ಧ', 35: 'ನ', 36: 'ಪ', 37: 'ಫ', 38: 'ಬ', 39: 'ಭ', 40: 'ಮ', 41: 'ಯ', 42: 'ರ', 43: 'ಲ', 44: 'ಳ', 45: 'ವ', 46: 'ಶ', 47: 'ಷ', 48: 'ಸ', 49: 'ಹ', 50: 'ಾ', 51: 'ಿ', 52: 'ೀ', 53: 'ು', 54: 'ೂ', 55: 'ೃ', 56: 'ೆ', 57: 'ೇ', 58: 'ೈ', 59: 'ೊ', 60: 'ೋ', 61: 'ೌ', 62: '್'}\n",
      "{0: '<', 1: '>', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e', 7: 'f', 8: 'g', 9: 'h', 10: 'i', 11: 'j', 12: 'k', 13: 'l', 14: 'm', 15: 'n', 16: 'o', 17: 'p', 18: 'q', 19: 'r', 20: 's', 21: 't', 22: 'u', 23: 'v', 24: 'w', 25: 'x', 26: 'y', 27: 'z'}\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = max([len(x) for x in X_train] + [len(y) for y in y_train])\n",
    "\n",
    "unique_chars = set()\n",
    "[unique_chars.update(list(x)) for x in y_train]\n",
    "unique_chars = list(unique_chars)\n",
    "unique_chars.sort()\n",
    "\n",
    "local_script = Script(language)\n",
    "local_script.create_vocab(unique_chars)\n",
    "print(local_script.inx2char)\n",
    "\n",
    "\n",
    "\n",
    "unique_chars = set()\n",
    "[unique_chars.update(list(x)) for x in X_train]\n",
    "unique_chars = list(unique_chars)\n",
    "unique_chars.sort()\n",
    "\n",
    "latin_script = Script('latin')\n",
    "latin_script.create_vocab(unique_chars)\n",
    "print(latin_script.inx2char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transliter_pairs_test = list(zip(X_test, y_test))\n",
    "transliter_pairs_train = list(zip(X_train, y_train))\n",
    "transliter_pairs_val = list(zip(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(transliter_pairs, latin_script, local_script, batch_size=32):\n",
    "    n = len(transliter_pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=int)\n",
    "    output_ids = np.zeros((n, MAX_LENGTH), dtype=int)\n",
    "\n",
    "\n",
    "    for idx, (latin, local) in enumerate(transliter_pairs):\n",
    "        inp_ids = [latin_script.char2idx[c] for c in latin]\n",
    "        out_ids = [local_script.char2idx[c] for c in local]\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        output_ids[idx, :len(out_ids)] = out_ids\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(output_ids).to(device))\n",
    "    sampler = torch.utils.data.RandomSampler(dataset)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, sampler=sampler, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = get_dataloader(transliter_pairs_train, latin_script, local_script, batch_size=32)\n",
    "dataloader_test = get_dataloader(transliter_pairs_test, latin_script, local_script, batch_size=32)\n",
    "dataloader_val = get_dataloader(transliter_pairs_val, latin_script, local_script, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = torch.nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(0)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = torch.nn.functional.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = torch.nn.functional.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "batch_size=32\n",
    "encoder = Encoder(input_size=latin_script.vocab_size, hidden_size=hidden_size, dropout_p=0).to(device)\n",
    "decoder = DecoderRNN(hidden_size=hidden_size, output_size=local_script.vocab_size).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, accuracy_criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_accuracy = torch.tensor([], dtype=torch.float32, device=device)\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "        accuracy = accuracy_criterion(decoded_ids, target_tensor)\n",
    "        total_accuracy = torch.cat((total_accuracy, accuracy))\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader), total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_val_loss_accuracy(val_dataloader, criterion, encoder, decoder):\n",
    "    total_loss = 0\n",
    "    for data in val_dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        # calcluating accuracy\n",
    "        \n",
    "\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100, val_dataloader=None):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    print_accuracy_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    accuracy_criterion = Accuracy(task='multiclass', num_classes=local_script.vocab_size, multidim_average='samplewise')\n",
    "\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss, accuracy = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, accuracy_criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        print_accuracy_total += sum(accuracy ==1)/len(accuracy)\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_accuracy_avg = print_accuracy_total / print_every\n",
    "            print_accuracy_total = 0\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) Loss: %.4f Acc: %.2f %%' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg, print_accuracy_avg*100))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 42s (- 6m 21s) (1 10%) Loss: 0.1417 Acc: 31.66 %\n",
      "1m 22s (- 5m 29s) (2 20%) Loss: 0.1136 Acc: 38.28 %\n",
      "2m 3s (- 4m 47s) (3 30%) Loss: 0.1095 Acc: 39.68 %\n",
      "2m 45s (- 4m 7s) (4 40%) Loss: 0.1063 Acc: 40.39 %\n",
      "3m 27s (- 3m 27s) (5 50%) Loss: 0.1031 Acc: 41.38 %\n",
      "4m 9s (- 2m 46s) (6 60%) Loss: 0.1014 Acc: 41.64 %\n",
      "4m 53s (- 2m 5s) (7 70%) Loss: 0.0996 Acc: 42.39 %\n",
      "5m 36s (- 1m 24s) (8 80%) Loss: 0.0972 Acc: 43.40 %\n",
      "6m 18s (- 0m 42s) (9 90%) Loss: 0.0957 Acc: 43.71 %\n",
      "7m 2s (- 0m 0s) (10 100%) Loss: 0.0937 Acc: 44.35 %\n"
     ]
    }
   ],
   "source": [
    "loss = train(dataloader_train, encoder, decoder, 10, print_every=1, plot_every=1)\n",
    "\n",
    "# for i in range(1000):\n",
    "#     losss = train_epoch(dataloader, encoder, decoder, torch.optim.Adam(encoder.parameters()), torch.optim.Adam(decoder.parameters()), torch.nn.NLLLoss())\n",
    "#     print(losss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = iter(dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ['<maatru>', '<madisikondiddaru>', '<samipawagideyo>', '<surimale>', '<dattavaagide>', '<matadaararannu>', '<madarasinalli>', '<huber>', '<munduwaridare>', '<maadikollabekembudu>', '<bittithu>', '<hoovinalli>', '<anugunavada>', '<lokasabege>', '<bittilla>', '<sab>', '<hakabahude>', '<gurutisuvikegalive>', '<kottawaru>', '<poornagolisabaeku>', '<thotagarikeye>', '<kanikegala>', '<he>', '<chakrabortty>', '<heelabahudaada>', '<south>', '<grahisi>', '<gattigolisabahudaagide>', '<seleyuttiddaarendu>', '<kreedaapatugalu>', '<pattehacchabahudu>', '<kattalu>']\n",
      "Expected: ['<ಮಾತೃ>', '<ಮಾಡಿಸಿಕೊಂಡಿದ್ದರು>', '<ಸಮೀಪವಾಗಿದೆಯೋ>', '<ಸುರಿಮಳೆ>', '<ದಟ್ಟವಾಗಿದೆ>', '<ಮತದಾರರನ್ನು>', '<ಮದರಾಸಿನಲ್ಲಿ>', '<ಹುಬರ್>', '<ಮುಂದುವರಿದರೆ>', '<ಮಾಡಿಕೊಳ್ಳಬೇಕೆಂಬುದು>', '<ಬಿಟ್ಟಿತು>', '<ಹೂವಿನಲ್ಲಿ>', '<ಅನುಗುಣವಾದ>', '<ಲೋಕಸಭೆಗೆ>', '<ಬಿಟ್ಟಿಲ್ಲ>', '<ಸಬ್>', '<ಹಾಕಬಹುದೇ>', '<ಗುರುತಿಸುವಿಕೆಗಳಿವೆ>', '<ಕೊಟ್ಟವರು>', '<ಪೂರ್ಣಗೊಳಿಸಬೇಕು>', '<ತೋಟಗಾರಿಕೆಯೇ>', '<ಕಾಣಿಕೆಗಳ>', '<ಹೆ>', '<ಚಕ್ರವರ್ತಿ>', '<ಹೇಳಬಹುದಾದ>', '<ಸೌಥ್>', '<ಗ್ರಹಿಸಿ>', '<ಗಟ್ಟಿಗೊಳಿಸಬಹುದಾಗಿದೆ>', '<ಸೆಳೆಯುತ್ತಿದ್ದಾರೆಂದು>', '<ಕ್ರೀಡಾಪಟುಗಳು>', '<ಪತ್ತೆಹಚ್ಚಬಹುದು>', '<ಕತ್ತಲು>']\n",
      "Predicted: ['<ಮಾತ್ರು>', '<ಮಾಡಿಸಿಕೊಂಡಿದ್ದರು>', '<ಸಮಿಪವಾಗಿದೆಯೋ>', '<ಸುರಿಮಲೆ>', '<ದತ್ತವಾಗಿದೆ>', '<ಮಾತಾದರರನ್ನು>', '<ಮದರಸಿನಲ್ಲಿ>', '<ಹುಬೆರ್>', '<ಮುಂದುವರಿದರೆ>', '<ಮಾಡಿಕೊಳ್ಳಬೇಕೆಂಬುದು>', '<ಬಿಟ್ಟಿತು>', '<ಹೂವಿನಲ್ಲಿ>', '<ಅನುಗುಣವೇಡ>', '<ಲೋಕಸಾದೆಲ್>', '<ಬಿಟ್ಟಿಲ್ಲ>', '<ಸಬ್>', '<ಹಾಕಬಹುದೇ>', '<ಗುರುತಿಸುವುದಿನಿಂತಲೇ>', '<ಕೊಟ್ಟಾವರು>', '<ಪೂರ್ಣಗೊಳಿಸಬೇಕಾದ>', '<ತೊಹಾತರಿಗೇಷ್>', '<ಕಣಿಕೆಗಳ>', '<ಹೆಯು>', '<ಚಾಕ್ರೋಸುತ್ತಿ>', '<ಹೇಳಿಬಹದದು>', '<ಸೌತ್>', '<ಗ್ರಹಿಸಿ>', '<ಗಟ್ಟಿಗೊಳಿಸಬಾಡದಿಗೂ>', '<ಸೆಳೆಯುತ್ತಿದ್ದಾರೆಂದು>', '<ಕ್ರೀಡಾಪಟುಗಳು>', '<ಪಟ್ಟೆಹಚೇಕೊಡುತ>', '<ಕಟ್ಟಲು>']\n",
      "Accuracy:   0.34375\n",
      "Matched:  {'<ಹಾಕಬಹುದೇ>', '<ಹೂವಿನಲ್ಲಿ>', '<ಸೆಳೆಯುತ್ತಿದ್ದಾರೆಂದು>', '<ಬಿಟ್ಟಿಲ್ಲ>', '<ಬಿಟ್ಟಿತು>', '<ಗ್ರಹಿಸಿ>', '<ಮಾಡಿಸಿಕೊಂಡಿದ್ದರು>', '<ಸಬ್>', '<ಮುಂದುವರಿದರೆ>', '<ಮಾಡಿಕೊಳ್ಳಬೇಕೆಂಬುದು>', '<ಕ್ರೀಡಾಪಟುಗಳು>'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convert_tensor_to_string(tensor, script):\n",
    "    words = []\n",
    "    for idx in tensor:\n",
    "        word = []\n",
    "        for i in idx:\n",
    "            word.append(script.inx2char[i.item()])\n",
    "            if i.item() == script.char2idx[END]:\n",
    "                break\n",
    "        words.append(''.join(word))\n",
    "    return words\n",
    "\n",
    "input_tensor, target_tensor = next(test_data)\n",
    "encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "_, topi = decoder_outputs.topk(1)\n",
    "decoded_ids = topi.squeeze()\n",
    "\n",
    "input_words, output_words = convert_tensor_to_string(input_tensor, latin_script), convert_tensor_to_string(decoded_ids, local_script)\n",
    "expected_words = convert_tensor_to_string(target_tensor, local_script)\n",
    "\n",
    "print('Input:', input_words)\n",
    "print('Expected:', expected_words)\n",
    "print('Predicted:', output_words)\n",
    "\n",
    "matched_words = set(expected_words) & set(output_words)\n",
    "print('Accuracy:  ', len(matched_words)/ len(expected_words))\n",
    "print('Matched: ', matched_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(torch.nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = torch.nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(0)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = torch.nn.functional.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_size=latin_script.vocab_size, hidden_size=hidden_size, dropout_p=0).to(device)\n",
    "attn_decoder = AttnDecoderRNN(hidden_size=hidden_size, output_size=local_script.vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 7s (- 1m 10s) (1 10%) Loss: 0.0958 Acc: 49.54 %\n",
      "0m 14s (- 0m 59s) (2 20%) Loss: 0.0692 Acc: 57.08 %\n",
      "0m 21s (- 0m 50s) (3 30%) Loss: 0.0567 Acc: 61.16 %\n",
      "0m 28s (- 0m 43s) (4 40%) Loss: 0.0494 Acc: 64.70 %\n",
      "0m 35s (- 0m 35s) (5 50%) Loss: 0.0448 Acc: 68.38 %\n",
      "0m 42s (- 0m 28s) (6 60%) Loss: 0.0388 Acc: 70.90 %\n",
      "0m 49s (- 0m 21s) (7 70%) Loss: 0.0342 Acc: 74.51 %\n",
      "0m 57s (- 0m 14s) (8 80%) Loss: 0.0441 Acc: 69.46 %\n",
      "1m 4s (- 0m 7s) (9 90%) Loss: 0.0356 Acc: 72.95 %\n",
      "1m 11s (- 0m 0s) (10 100%) Loss: 0.0270 Acc: 79.03 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09581073725712486,\n",
       " 0.06917410116875544,\n",
       " 0.056681876856600866,\n",
       " 0.049391484397347085,\n",
       " 0.04484878754010424,\n",
       " 0.03883489684085362,\n",
       " 0.0341956235060934,\n",
       " 0.0441437107292586,\n",
       " 0.035578380222432315,\n",
       " 0.027031289704609662]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(dataloader_test, encoder, attn_decoder, 10, print_every=1, plot_every=1, val_dataloader=dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ['<nadusuttiruva>', '<shouchalayada>', '<vidisha>', '<kayideyadiyalli>', '<nadesalaguttiruvudara>', '<celebrity>', '<chenda>', '<dakhalisuttiddavu>', '<barutte>', '<meghwal>', '<rajakeeyawannu>', '<rajasthanada>', '<hasyada>', '<glendale>', '<aaykeyinda>', '<gurjar>', '<vyavakarisiruvudu>', '<vyaaptiyannu>', '<pragatiyallide>', '<patrick>', '<madhyantharadalli>', '<sthaanada>', '<wyawasteyalliyae>', '<shrimantarige>', '<marupavati>', '<mikkida>', '<anant>', '<fals>', '<paroxawaagi>', '<haadihogalutthale>', '<ulisikolluttiddu>', '<upakathanawoo>']\n",
      "Expected: ['<ನಡೆಸುತ್ತಿರುವ>', '<ಶೌಚಾಲಯದ>', '<ವಿದಿಶಾ>', '<ಕಾಯಿದೆಯಡಿಯಲ್ಲಿ>', '<ನಡೆಸಲಾಗುತ್ತಿರುವುದರ>', '<ಸೆಲೆಬ್ರಿಟಿ>', '<ಚೆಂದ>', '<ದಾಖಲಿಸುತ್ತಿದ್ದವು>', '<ಬರುತ್ತೆ>', '<ಮೇಘ್ವಾಲ್>', '<ರಾಜಕೀಯವನ್ನು>', '<ರಾಜಸ್ತಾನದ>', '<ಹಾಸ್ಯದ>', '<ಗ್ಲೆಂಡೇಲ್>', '<ಆಯ್ಕೆಯಿಂದ>', '<ಗುರ್ಜಾರ್>', '<ವ್ಯವಕರಿಸಿರುವುದು>', '<ವ್ಯಾಪ್ತಿಯನ್ನು>', '<ಪ್ರಗತಿಯಲ್ಲಿದೆ>', '<ಪ್ಯಾಟ್ರಿಕ್>', '<ಮಧ್ಯಂತರದಲ್ಲಿ>', '<ಸ್ಥಾನದ>', '<ವ್ಯವಸ್ಥೆಯಲ್ಲಿಯೇ>', '<ಶ್ರೀಮಂತರಿಗೆ>', '<ಮರುಪಾವತಿ>', '<ಮಿಕ್ಕಿದ>', '<ಅನಂತ್>', '<ಫಾಲ್ಸ್>', '<ಪರೋಕ್ಷವಾಗಿ>', '<ಹಾಡಿಹೊಗಳುತ್ತಲೇ>', '<ಉಳಿಸಿಕೊಳ್ಳುತ್ತಿದ್ದು>', '<ಉಪಕಥನವೂ>']\n",
      "Predicted: ['<ನಡುಸುತ್ತಿರುವ>', '<ಶೌಚಾಲಯದ>', '<ವಿದಿಶ>', '<ಕಾಯಿದೆಯಡಿಯಲ್ಲಿ>', '<ನಡೆಸಲಾಗುತ್ತಿರುವುದರ>', '<ಸೆಲೆಬ್ರಿಟಿ>', '<ಚೆಂದ>', '<ದಾಖಲಿಸುತ್ತಿದ್ದವು>', '<ಬರುತ್ತೆ>', '<ಮೇಘ್ವಾಲ್>', '<ರಾಜಕೀಯವನ್ನು>', '<ರಾಜಸ್ತಾನದ>', '<ಹಸ್ಯದ>', '<ಗ್ಲೆಂಡೇಲ್>', '<ಆಯ್ಕೆಯಿಂದ>', '<ಗುರ್ಜಾರ್>', '<ವ್ಯವಕರಿಸಿರುವುದು>', '<ವ್ಯಾಪ್ತಿಯನ್ನು>', '<ಪ್ರಗತಿಯಲ್ಲಿದೆ>', '<ಪ್ಯಾಟ್ರಿಕ್>', '<ಮಧ್ಯಂತರದಲ್ಲಿ>', '<ಸ್ಥಾನದ>', '<ವ್ಯವಸ್ಥೆಯಲ್ಲಿಯೇ>', '<ಶ್ರೀಮಂತರಿಗೆ>', '<ಮರುಪಾವತಿ>', '<ಮಿಕ್ಕಿದ>', '<ಅನಂತ್>', '<ಫಾಲ್ಸ್>', '<ಪರೋಕ್ಷವಾಗಿ>', '<ಹಾಡಿಹೊಗಳುತ್ತಲೇ>', '<ಉಳಿಸಿಕೊಳ್ಳುತ್ತಿದ್ದು>', '<ಉಪಕಥನವೂ>']\n",
      "Accuracy:   0.90625\n",
      "Matched:  {'<ಉಪಕಥನವೂ>', '<ಆಯ್ಕೆಯಿಂದ>', '<ಉಳಿಸಿಕೊಳ್ಳುತ್ತಿದ್ದು>', '<ಕಾಯಿದೆಯಡಿಯಲ್ಲಿ>', '<ವ್ಯವಸ್ಥೆಯಲ್ಲಿಯೇ>', '<ಮರುಪಾವತಿ>', '<ಹಾಡಿಹೊಗಳುತ್ತಲೇ>', '<ಪ್ಯಾಟ್ರಿಕ್>', '<ಬರುತ್ತೆ>', '<ಗುರ್ಜಾರ್>', '<ಚೆಂದ>', '<ಪರೋಕ್ಷವಾಗಿ>', '<ಗ್ಲೆಂಡೇಲ್>', '<ಸೆಲೆಬ್ರಿಟಿ>', '<ಅನಂತ್>', '<ಶ್ರೀಮಂತರಿಗೆ>', '<ನಡೆಸಲಾಗುತ್ತಿರುವುದರ>', '<ರಾಜಸ್ತಾನದ>', '<ರಾಜಕೀಯವನ್ನು>', '<ಪ್ರಗತಿಯಲ್ಲಿದೆ>', '<ಮಧ್ಯಂತರದಲ್ಲಿ>', '<ದಾಖಲಿಸುತ್ತಿದ್ದವು>', '<ಶೌಚಾಲಯದ>', '<ವ್ಯಾಪ್ತಿಯನ್ನು>', '<ವ್ಯವಕರಿಸಿರುವುದು>', '<ಮಿಕ್ಕಿದ>', '<ಮೇಘ್ವಾಲ್>', '<ಸ್ಥಾನದ>', '<ಫಾಲ್ಸ್>'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convert_tensor_to_string(tensor, script):\n",
    "    words = []\n",
    "    for idx in tensor:\n",
    "        word = []\n",
    "        for i in idx:\n",
    "            word.append(script.inx2char[i.item()])\n",
    "            if i.item() == script.char2idx[END]:\n",
    "                break\n",
    "        words.append(''.join(word))\n",
    "    return words\n",
    "\n",
    "input_tensor, target_tensor = next(test_data)\n",
    "encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "decoder_outputs, _, _ = attn_decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "_, topi = decoder_outputs.topk(1)\n",
    "decoded_ids = topi.squeeze()\n",
    "\n",
    "input_words, output_words = convert_tensor_to_string(input_tensor, latin_script), convert_tensor_to_string(decoded_ids, local_script)\n",
    "expected_words = convert_tensor_to_string(target_tensor, local_script)\n",
    "\n",
    "print('Input:', input_words)\n",
    "print('Expected:', expected_words)\n",
    "print('Predicted:', output_words)\n",
    "\n",
    "matched_words = set(expected_words) & set(output_words)\n",
    "print('Accuracy:  ', len(matched_words)/ len(expected_words))\n",
    "print('Matched: ', matched_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
